{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Voice Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T16:30:15.689556Z",
     "start_time": "2018-12-06T16:29:43.420772Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T16:41:01.299276Z",
     "start_time": "2018-12-06T16:41:01.288746Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data folder path\n",
    "file_path = '/Users/anatoli_debradke/Desktop/Speech Emotion Analysis/RAVDESS/Data/'\n",
    "\n",
    "# Get all filenames from all actors\n",
    "file_names = mylist= os.listdir(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:38:44.580314Z",
     "start_time": "2018-12-04T16:38:44.560062Z"
    }
   },
   "source": [
    "### b. Set labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T16:41:02.685170Z",
     "start_time": "2018-12-06T16:41:02.663900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Label list\n",
    "label_list = []\n",
    "\n",
    "# Set all audio files labels\n",
    "for audio_file in file_names:\n",
    "    if audio_file[6:-16]=='02' and int(audio_file[18:-4])%2==0:\n",
    "        label_list.append('female_calm')\n",
    "    elif audio_file[6:-16]=='02' and int(audio_file[18:-4])%2==1:\n",
    "        label_list.append('male_calm')\n",
    "    elif audio_file[6:-16]=='03' and int(audio_file[18:-4])%2==0:\n",
    "        label_list.append('female_happy')\n",
    "    elif audio_file[6:-16]=='03' and int(audio_file[18:-4])%2==1:\n",
    "        label_list.append('male_happy')\n",
    "    elif audio_file[6:-16]=='04' and int(audio_file[18:-4])%2==0:\n",
    "        label_list.append('female_sad')\n",
    "    elif audio_file[6:-16]=='04' and int(audio_file[18:-4])%2==1:\n",
    "        label_list.append('male_sad')\n",
    "    elif audio_file[6:-16]=='05' and int(audio_file[18:-4])%2==0:\n",
    "        label_list.append('female_angry')\n",
    "    elif audio_file[6:-16]=='05' and int(audio_file[18:-4])%2==1:\n",
    "        label_list.append('male_angry')\n",
    "    elif audio_file[6:-16]=='06' and int(audio_file[18:-4])%2==0:\n",
    "        label_list.append('female_fearful')\n",
    "    elif audio_file[6:-16]=='06' and int(audio_file[18:-4])%2==1:\n",
    "        label_list.append('male_fearful')\n",
    "    elif audio_file[2:-6]=='a':\n",
    "        label_list.append('male_angry')\n",
    "    elif audio_file[2:-6]=='f':\n",
    "        label_list.append('male_fearful')\n",
    "    elif audio_file[2:-6]=='h':\n",
    "        label_list.append('male_happy')\n",
    "    elif audio_file[2:-6]=='sa':\n",
    "        label_list.append('male_sad')\n",
    "\n",
    "# Build dataframe with all label\n",
    "df_labels = pd.DataFrame(label_list, columns=['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T17:10:51.478413Z",
     "start_time": "2018-12-04T17:10:51.475113Z"
    }
   },
   "source": [
    "### c. Build Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T16:44:34.392645Z",
     "start_time": "2018-12-06T16:43:22.441707Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize DataFrame for features\n",
    "df_features = pd.DataFrame(columns=['features'])\n",
    "\n",
    "# Build all audio files features using librosa\n",
    "for audio_index, audio_file in enumerate(file_names):\n",
    "    \n",
    "    # Remove undesired label (NEUTRAL: (01,n), DISGUST: (07,d), SURPRISED: (08,su)\n",
    "    if audio_file[6:-16]!='01' and audio_file[6:-16]!='07' and audio_file[6:-16]!='08' and audio_file[2:-6]!='su' and audio_file[2:-6]!='n' and audio_file[2:-6]!='d':\n",
    "\n",
    "        # load audio file\n",
    "        X, sample_rate = librosa.load( file_path + audio_file, res_type='kaiser_fast', duration=2.5, sr=22050*2, offset=0.5)\n",
    "\n",
    "        # Calculate and add features to dataFrame\n",
    "        df_features.loc[audio_index] = [np.mean(librosa.feature.mfcc(y=X, sr=np.array(sample_rate), n_mfcc=13), axis=0)]\n",
    "\n",
    "# Split features column in dataFrame\n",
    "df_features = pd.DataFrame(df_features['features'].values.tolist())\n",
    "\n",
    "# Concatenate Features and Label Dataframe\n",
    "df = pd.concat([df_features, df_labels], axis=1)\n",
    "\n",
    "# Shuffle dataFrame\n",
    "df = shuffle(df)\n",
    "\n",
    "# Replace NA values\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### a. Build train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T16:45:20.991566Z",
     "start_time": "2018-12-06T16:45:20.975784Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build Train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['label'], axis=1), df['label'], test_size=0.2)\n",
    "\n",
    "# Cast to array\n",
    "X_train, X_test = np.array(X_train), np.array(X_test)\n",
    "y_train, y_test = np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Encode Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T16:45:22.492733Z",
     "start_time": "2018-12-06T16:45:22.482745Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode Label from categorical to numerical\n",
    "lb = LabelEncoder()\n",
    "y_train, y_test = np_utils.to_categorical(lb.fit_transform(y_train)), np_utils.to_categorical(lb.fit_transform(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T17:52:19.697638Z",
     "start_time": "2018-12-04T17:52:19.628855Z"
    }
   },
   "source": [
    "### c. Changing dimension for CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T16:45:23.954087Z",
     "start_time": "2018-12-06T16:45:23.948003Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape features train and test dataset\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T16:45:25.940476Z",
     "start_time": "2018-12-06T16:45:25.648080Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 216, 256)          1536      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 216, 128)          163968    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                34570     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 364,170\n",
      "Trainable params: 364,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize sequence (linear stack of layers)\n",
    "model = Sequential()\n",
    "\n",
    "# Add all Layers\n",
    "model.add(Conv1D(256, 5, padding='same', input_shape=(216, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=8))\n",
    "model.add(Conv1D(128, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Summarize CNN Model\n",
    "model.summary()\n",
    "\n",
    "# Compile CNN model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.rmsprop(lr=0.00001, decay=1e-6), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T10:59:10.378528Z",
     "start_time": "2018-12-05T10:59:10.375601Z"
    }
   },
   "source": [
    "### e. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-06T16:45:38.853Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 960 samples, validate on 240 samples\n",
      "Epoch 1/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 2.2932 - acc: 0.1490 - val_loss: 2.2600 - val_acc: 0.1958\n",
      "Epoch 2/700\n",
      "960/960 [==============================] - 12s 12ms/step - loss: 2.2362 - acc: 0.1771 - val_loss: 2.2211 - val_acc: 0.1500\n",
      "Epoch 3/700\n",
      "960/960 [==============================] - 13s 14ms/step - loss: 2.1993 - acc: 0.1854 - val_loss: 2.1993 - val_acc: 0.2208\n",
      "Epoch 4/700\n",
      "960/960 [==============================] - 12s 12ms/step - loss: 2.1714 - acc: 0.2115 - val_loss: 2.1840 - val_acc: 0.2000\n",
      "Epoch 5/700\n",
      "960/960 [==============================] - 12s 12ms/step - loss: 2.1492 - acc: 0.2208 - val_loss: 2.1485 - val_acc: 0.2083\n",
      "Epoch 6/700\n",
      "960/960 [==============================] - 14s 15ms/step - loss: 2.1202 - acc: 0.2458 - val_loss: 2.1352 - val_acc: 0.2125\n",
      "Epoch 7/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 2.0889 - acc: 0.2552 - val_loss: 2.1216 - val_acc: 0.2000\n",
      "Epoch 8/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 2.0727 - acc: 0.2719 - val_loss: 2.0911 - val_acc: 0.2375\n",
      "Epoch 9/700\n",
      "960/960 [==============================] - 8s 9ms/step - loss: 2.0482 - acc: 0.2781 - val_loss: 2.0721 - val_acc: 0.2625\n",
      "Epoch 10/700\n",
      "960/960 [==============================] - 10s 11ms/step - loss: 2.0234 - acc: 0.3052 - val_loss: 2.0583 - val_acc: 0.2292\n",
      "Epoch 11/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 2.0083 - acc: 0.3042 - val_loss: 2.0329 - val_acc: 0.2167\n",
      "Epoch 12/700\n",
      "960/960 [==============================] - 11s 11ms/step - loss: 1.9786 - acc: 0.3062 - val_loss: 2.0242 - val_acc: 0.2333\n",
      "Epoch 13/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.9515 - acc: 0.3104 - val_loss: 1.9795 - val_acc: 0.3000\n",
      "Epoch 14/700\n",
      "960/960 [==============================] - 11s 11ms/step - loss: 1.9318 - acc: 0.3229 - val_loss: 1.9654 - val_acc: 0.2833\n",
      "Epoch 15/700\n",
      "960/960 [==============================] - 9s 10ms/step - loss: 1.9010 - acc: 0.3271 - val_loss: 1.9414 - val_acc: 0.2708\n",
      "Epoch 16/700\n",
      "960/960 [==============================] - 10s 11ms/step - loss: 1.8801 - acc: 0.3333 - val_loss: 1.9067 - val_acc: 0.3167\n",
      "Epoch 17/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 1.8492 - acc: 0.3135 - val_loss: 1.9023 - val_acc: 0.2708\n",
      "Epoch 18/700\n",
      "960/960 [==============================] - 11s 11ms/step - loss: 1.8339 - acc: 0.3208 - val_loss: 1.8782 - val_acc: 0.2917\n",
      "Epoch 19/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.8080 - acc: 0.3583 - val_loss: 1.8572 - val_acc: 0.3375\n",
      "Epoch 20/700\n",
      "960/960 [==============================] - 12s 13ms/step - loss: 1.7886 - acc: 0.3667 - val_loss: 1.8671 - val_acc: 0.3167\n",
      "Epoch 21/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.7633 - acc: 0.3719 - val_loss: 1.8369 - val_acc: 0.2833\n",
      "Epoch 22/700\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 1.7519 - acc: 0.3823 - val_loss: 1.8205 - val_acc: 0.3208\n",
      "Epoch 23/700\n",
      "960/960 [==============================] - 9s 10ms/step - loss: 1.7294 - acc: 0.3781 - val_loss: 1.7952 - val_acc: 0.3250\n",
      "Epoch 24/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.7119 - acc: 0.3781 - val_loss: 1.7933 - val_acc: 0.3667\n",
      "Epoch 25/700\n",
      "960/960 [==============================] - 11s 11ms/step - loss: 1.6930 - acc: 0.4083 - val_loss: 1.7804 - val_acc: 0.2958\n",
      "Epoch 26/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 1.6771 - acc: 0.3979 - val_loss: 1.7851 - val_acc: 0.3375\n",
      "Epoch 27/700\n",
      "960/960 [==============================] - 9s 10ms/step - loss: 1.6600 - acc: 0.4021 - val_loss: 1.7660 - val_acc: 0.3292\n",
      "Epoch 28/700\n",
      "960/960 [==============================] - 9s 10ms/step - loss: 1.6447 - acc: 0.4125 - val_loss: 1.7468 - val_acc: 0.3208\n",
      "Epoch 29/700\n",
      "960/960 [==============================] - 9s 10ms/step - loss: 1.6325 - acc: 0.4104 - val_loss: 1.7191 - val_acc: 0.3375\n",
      "Epoch 30/700\n",
      "960/960 [==============================] - 10s 11ms/step - loss: 1.6221 - acc: 0.4083 - val_loss: 1.7229 - val_acc: 0.3208\n",
      "Epoch 31/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.5980 - acc: 0.3969 - val_loss: 1.7229 - val_acc: 0.3458\n",
      "Epoch 32/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.5851 - acc: 0.4146 - val_loss: 1.6989 - val_acc: 0.3833\n",
      "Epoch 33/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 1.5777 - acc: 0.4344 - val_loss: 1.6897 - val_acc: 0.3625\n",
      "Epoch 34/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 1.5692 - acc: 0.4354 - val_loss: 1.7026 - val_acc: 0.3375\n",
      "Epoch 35/700\n",
      "960/960 [==============================] - 9s 10ms/step - loss: 1.5571 - acc: 0.4365 - val_loss: 1.7080 - val_acc: 0.3125\n",
      "Epoch 36/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 1.5462 - acc: 0.4312 - val_loss: 1.6683 - val_acc: 0.4042\n",
      "Epoch 37/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 1.5292 - acc: 0.4448 - val_loss: 1.6752 - val_acc: 0.3875\n",
      "Epoch 38/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 1.5268 - acc: 0.4458 - val_loss: 1.6633 - val_acc: 0.3250\n",
      "Epoch 39/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 1.5154 - acc: 0.4573 - val_loss: 1.6522 - val_acc: 0.3708\n",
      "Epoch 40/700\n",
      "960/960 [==============================] - 8s 9ms/step - loss: 1.5071 - acc: 0.4500 - val_loss: 1.6294 - val_acc: 0.4083\n",
      "Epoch 41/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 1.4967 - acc: 0.4531 - val_loss: 1.6342 - val_acc: 0.3708\n",
      "Epoch 42/700\n",
      "960/960 [==============================] - 8s 9ms/step - loss: 1.4858 - acc: 0.4552 - val_loss: 1.6572 - val_acc: 0.3458\n",
      "Epoch 43/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.4778 - acc: 0.4552 - val_loss: 1.6333 - val_acc: 0.3833\n",
      "Epoch 44/700\n",
      "960/960 [==============================] - 8s 8ms/step - loss: 1.4695 - acc: 0.4573 - val_loss: 1.6219 - val_acc: 0.3958\n",
      "Epoch 45/700\n",
      "960/960 [==============================] - 9s 10ms/step - loss: 1.4712 - acc: 0.4531 - val_loss: 1.6309 - val_acc: 0.3917\n",
      "Epoch 46/700\n",
      "960/960 [==============================] - 9s 10ms/step - loss: 1.4528 - acc: 0.4771 - val_loss: 1.6054 - val_acc: 0.3917\n",
      "Epoch 47/700\n",
      "960/960 [==============================] - 9s 10ms/step - loss: 1.4450 - acc: 0.4740 - val_loss: 1.6200 - val_acc: 0.3875\n",
      "Epoch 48/700\n",
      "960/960 [==============================] - 8s 8ms/step - loss: 1.4399 - acc: 0.4771 - val_loss: 1.6085 - val_acc: 0.3792\n",
      "Epoch 49/700\n",
      "960/960 [==============================] - 8s 8ms/step - loss: 1.4344 - acc: 0.4875 - val_loss: 1.6117 - val_acc: 0.3750\n",
      "Epoch 50/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.4260 - acc: 0.4792 - val_loss: 1.6097 - val_acc: 0.3708\n",
      "Epoch 51/700\n",
      "960/960 [==============================] - 9s 10ms/step - loss: 1.4203 - acc: 0.4823 - val_loss: 1.6139 - val_acc: 0.3375\n",
      "Epoch 52/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.4067 - acc: 0.4813 - val_loss: 1.6265 - val_acc: 0.3750\n",
      "Epoch 53/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.4061 - acc: 0.4760 - val_loss: 1.5905 - val_acc: 0.3833\n",
      "Epoch 54/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 1.3926 - acc: 0.4781 - val_loss: 1.6077 - val_acc: 0.3958\n",
      "Epoch 55/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.3954 - acc: 0.4917 - val_loss: 1.5800 - val_acc: 0.3917\n",
      "Epoch 56/700\n",
      "960/960 [==============================] - 11s 11ms/step - loss: 1.3907 - acc: 0.4802 - val_loss: 1.5739 - val_acc: 0.3833\n",
      "Epoch 57/700\n",
      "960/960 [==============================] - 9s 10ms/step - loss: 1.3826 - acc: 0.4760 - val_loss: 1.5618 - val_acc: 0.4042\n",
      "Epoch 58/700\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 1.3745 - acc: 0.5062 - val_loss: 1.5757 - val_acc: 0.3667\n",
      "Epoch 59/700\n",
      "960/960 [==============================] - 12s 12ms/step - loss: 1.3686 - acc: 0.4948 - val_loss: 1.5935 - val_acc: 0.3708\n",
      "Epoch 60/700\n",
      "960/960 [==============================] - 11s 11ms/step - loss: 1.3647 - acc: 0.5062 - val_loss: 1.5923 - val_acc: 0.3625\n",
      "Epoch 61/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 8s 8ms/step - loss: 1.3576 - acc: 0.5042 - val_loss: 1.5649 - val_acc: 0.3958\n",
      "Epoch 62/700\n",
      "960/960 [==============================] - 8s 9ms/step - loss: 1.3543 - acc: 0.4969 - val_loss: 1.5832 - val_acc: 0.3625\n",
      "Epoch 63/700\n",
      "960/960 [==============================] - 8s 8ms/step - loss: 1.3438 - acc: 0.5104 - val_loss: 1.5642 - val_acc: 0.3500\n",
      "Epoch 64/700\n",
      "960/960 [==============================] - 8s 9ms/step - loss: 1.3366 - acc: 0.5219 - val_loss: 1.5704 - val_acc: 0.3708\n",
      "Epoch 65/700\n",
      "960/960 [==============================] - 10s 11ms/step - loss: 1.3261 - acc: 0.5135 - val_loss: 1.5890 - val_acc: 0.3750\n",
      "Epoch 66/700\n",
      "960/960 [==============================] - 8s 9ms/step - loss: 1.3309 - acc: 0.5042 - val_loss: 1.5652 - val_acc: 0.3958\n",
      "Epoch 67/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.3278 - acc: 0.5052 - val_loss: 1.5976 - val_acc: 0.3833\n",
      "Epoch 68/700\n",
      "960/960 [==============================] - 8s 9ms/step - loss: 1.3205 - acc: 0.5219 - val_loss: 1.5837 - val_acc: 0.4042\n",
      "Epoch 69/700\n",
      "960/960 [==============================] - 8s 9ms/step - loss: 1.3117 - acc: 0.5104 - val_loss: 1.5649 - val_acc: 0.3917\n",
      "Epoch 70/700\n",
      "960/960 [==============================] - 12s 12ms/step - loss: 1.3148 - acc: 0.5167 - val_loss: 1.5687 - val_acc: 0.3750\n",
      "Epoch 71/700\n",
      "960/960 [==============================] - 13s 13ms/step - loss: 1.2995 - acc: 0.5240 - val_loss: 1.5447 - val_acc: 0.4042\n",
      "Epoch 72/700\n",
      "960/960 [==============================] - 13s 13ms/step - loss: 1.3022 - acc: 0.5302 - val_loss: 1.5605 - val_acc: 0.3750\n",
      "Epoch 73/700\n",
      "960/960 [==============================] - 14s 14ms/step - loss: 1.2923 - acc: 0.5406 - val_loss: 1.5603 - val_acc: 0.4167\n",
      "Epoch 74/700\n",
      "960/960 [==============================] - 12s 13ms/step - loss: 1.2850 - acc: 0.5250 - val_loss: 1.5618 - val_acc: 0.3625\n",
      "Epoch 75/700\n",
      "960/960 [==============================] - 10s 11ms/step - loss: 1.2862 - acc: 0.5250 - val_loss: 1.5655 - val_acc: 0.3750\n",
      "Epoch 76/700\n",
      "960/960 [==============================] - 8s 8ms/step - loss: 1.2758 - acc: 0.5406 - val_loss: 1.5435 - val_acc: 0.3875\n",
      "Epoch 77/700\n",
      "960/960 [==============================] - 10s 11ms/step - loss: 1.2740 - acc: 0.5323 - val_loss: 1.5350 - val_acc: 0.3708\n",
      "Epoch 78/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.2650 - acc: 0.5427 - val_loss: 1.5460 - val_acc: 0.3833\n",
      "Epoch 79/700\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 1.2635 - acc: 0.5354 - val_loss: 1.5630 - val_acc: 0.4083\n",
      "Epoch 80/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.2526 - acc: 0.5490 - val_loss: 1.5527 - val_acc: 0.4292\n",
      "Epoch 81/700\n",
      "960/960 [==============================] - 8s 9ms/step - loss: 1.2591 - acc: 0.5323 - val_loss: 1.5543 - val_acc: 0.3917\n",
      "Epoch 82/700\n",
      "960/960 [==============================] - 11s 11ms/step - loss: 1.2518 - acc: 0.5510 - val_loss: 1.5187 - val_acc: 0.4125\n",
      "Epoch 83/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.2417 - acc: 0.5438 - val_loss: 1.5351 - val_acc: 0.4000\n",
      "Epoch 84/700\n",
      "960/960 [==============================] - 8s 8ms/step - loss: 1.2369 - acc: 0.5521 - val_loss: 1.5412 - val_acc: 0.3833\n",
      "Epoch 85/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 1.2380 - acc: 0.5531 - val_loss: 1.5158 - val_acc: 0.3750\n",
      "Epoch 86/700\n",
      "960/960 [==============================] - 8s 8ms/step - loss: 1.2420 - acc: 0.5542 - val_loss: 1.5324 - val_acc: 0.4292\n",
      "Epoch 87/700\n",
      "960/960 [==============================] - 8s 9ms/step - loss: 1.2311 - acc: 0.5427 - val_loss: 1.5392 - val_acc: 0.3667\n",
      "Epoch 88/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 1.2296 - acc: 0.5344 - val_loss: 1.5332 - val_acc: 0.4042\n",
      "Epoch 89/700\n",
      "960/960 [==============================] - 8s 9ms/step - loss: 1.2120 - acc: 0.5594 - val_loss: 1.5120 - val_acc: 0.4042\n",
      "Epoch 90/700\n",
      "960/960 [==============================] - 8s 9ms/step - loss: 1.2144 - acc: 0.5521 - val_loss: 1.5481 - val_acc: 0.4333\n",
      "Epoch 91/700\n",
      "960/960 [==============================] - 8s 8ms/step - loss: 1.2072 - acc: 0.5531 - val_loss: 1.5337 - val_acc: 0.3708\n",
      "Epoch 92/700\n",
      "960/960 [==============================] - 9s 10ms/step - loss: 1.2137 - acc: 0.5615 - val_loss: 1.5063 - val_acc: 0.4208\n",
      "Epoch 93/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.2084 - acc: 0.5635 - val_loss: 1.5023 - val_acc: 0.4125\n",
      "Epoch 94/700\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 1.1954 - acc: 0.5687 - val_loss: 1.5369 - val_acc: 0.3833\n",
      "Epoch 95/700\n",
      "960/960 [==============================] - 11s 11ms/step - loss: 1.1982 - acc: 0.5615 - val_loss: 1.5287 - val_acc: 0.4083\n",
      "Epoch 96/700\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 1.1963 - acc: 0.5615 - val_loss: 1.5143 - val_acc: 0.3917\n",
      "Epoch 97/700\n",
      "960/960 [==============================] - 10s 11ms/step - loss: 1.1859 - acc: 0.5740 - val_loss: 1.5040 - val_acc: 0.4000\n",
      "Epoch 98/700\n",
      "960/960 [==============================] - 11s 11ms/step - loss: 1.1799 - acc: 0.5604 - val_loss: 1.5495 - val_acc: 0.3833\n",
      "Epoch 99/700\n",
      "960/960 [==============================] - 10s 11ms/step - loss: 1.1756 - acc: 0.5833 - val_loss: 1.5129 - val_acc: 0.4208\n",
      "Epoch 100/700\n",
      "960/960 [==============================] - 12s 12ms/step - loss: 1.1793 - acc: 0.5583 - val_loss: 1.5044 - val_acc: 0.3917\n",
      "Epoch 101/700\n",
      "960/960 [==============================] - 10s 11ms/step - loss: 1.1791 - acc: 0.5760 - val_loss: 1.5092 - val_acc: 0.3708\n",
      "Epoch 102/700\n",
      "960/960 [==============================] - 10s 11ms/step - loss: 1.1624 - acc: 0.5865 - val_loss: 1.5141 - val_acc: 0.3792\n",
      "Epoch 103/700\n",
      "960/960 [==============================] - 9s 10ms/step - loss: 1.1677 - acc: 0.5958 - val_loss: 1.5025 - val_acc: 0.4125\n",
      "Epoch 104/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.1582 - acc: 0.5792 - val_loss: 1.4976 - val_acc: 0.3792\n",
      "Epoch 105/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.1590 - acc: 0.5823 - val_loss: 1.5291 - val_acc: 0.3917\n",
      "Epoch 106/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 1.1511 - acc: 0.5875 - val_loss: 1.5235 - val_acc: 0.3750\n",
      "Epoch 107/700\n",
      "960/960 [==============================] - 9s 9ms/step - loss: 1.1499 - acc: 0.5969 - val_loss: 1.5401 - val_acc: 0.4333\n",
      "Epoch 108/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.1437 - acc: 0.5865 - val_loss: 1.4908 - val_acc: 0.4000\n",
      "Epoch 109/700\n",
      "960/960 [==============================] - 11s 11ms/step - loss: 1.1360 - acc: 0.5823 - val_loss: 1.5300 - val_acc: 0.3917\n",
      "Epoch 110/700\n",
      "960/960 [==============================] - 10s 10ms/step - loss: 1.1477 - acc: 0.6021 - val_loss: 1.5077 - val_acc: 0.4375\n",
      "Epoch 111/700\n",
      "960/960 [==============================] - 8s 8ms/step - loss: 1.1305 - acc: 0.6031 - val_loss: 1.5087 - val_acc: 0.3750\n",
      "Epoch 112/700\n",
      "960/960 [==============================] - 8s 9ms/step - loss: 1.1373 - acc: 0.6198 - val_loss: 1.5064 - val_acc: 0.3833\n",
      "Epoch 113/700\n",
      "192/960 [=====>........................] - ETA: 6s - loss: 1.0786 - acc: 0.6354"
     ]
    }
   ],
   "source": [
    "cnn = model.fit(X_train, y_train, batch_size=16, epochs=700, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Model Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:58:29.788721Z",
     "start_time": "2018-12-05T21:58:29.428974Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(0, figsize=(20, 20))\n",
    "\n",
    "# Plot Model loss\n",
    "plt.subplot(221)\n",
    "plt.plot(cnn.history['loss'], label='train')\n",
    "plt.plot(cnn.history['val_loss'], label='test')\n",
    "plt.title('model loss', fontsize = 16)\n",
    "plt.ylabel('loss'); plt.xlabel('epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Plot Model Accuracy\n",
    "plt.subplot(222)\n",
    "plt.plot(cnn.history['acc'], label='train')\n",
    "plt.plot(cnn.history['val_acc'], label='test')\n",
    "plt.title('model accuracy', fontsize = 16)\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T11:11:59.303292Z",
     "start_time": "2018-12-05T11:11:59.297736Z"
    }
   },
   "source": [
    "### g. Predict emotion on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T22:42:47.916122Z",
     "start_time": "2018-12-05T22:42:47.377744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "pred = model.predict(X_test, batch_size=32, verbose=0)\n",
    "\n",
    "# Score\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Get the index of the max 'probability' for prediction and actual\n",
    "pred = pred.argmax(axis=1)\n",
    "actual = y_test.argmax(axis=1)\n",
    "\n",
    "# Reverse label encoder\n",
    "pred = (lb.inverse_transform((pred.astype(int).flatten())))\n",
    "actual = (lb.inverse_transform((actual.astype(int).flatten())))\n",
    "\n",
    "# Build dataFrame\n",
    "df_pred = pd.DataFrame({'Actual': actual, 'Prediction': pred})\n",
    "\n",
    "# Commentary\n",
    "print('Accuracy Score on test dataset: {}%'.format(np.round(100 * score[1],2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h. Test on personnal audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T22:35:20.721448Z",
     "start_time": "2018-12-05T22:35:20.640170Z"
    }
   },
   "outputs": [],
   "source": [
    "# Audio File path\n",
    "filenames = ['/Users/anatoli_debradke/Desktop/Speech Emotion Analysis/AudioData/DC/a03.wav', '/Users/anatoli_debradke/Desktop/Speech Emotion Analysis/AudioData/JK/su07.wav']\n",
    "\n",
    "# Initialize DataFrame for features\n",
    "df_features = pd.DataFrame(columns=['features'])\n",
    "\n",
    "# Build all audio files features using librosa\n",
    "for audio_index, audio_file in enumerate(filenames):\n",
    "    \n",
    "    # load audio file\n",
    "    X, sample_rate = librosa.load(audio_file, res_type='kaiser_fast', duration=2.5, sr=22050*2, offset=0.5)\n",
    "    \n",
    "    # Calculate and add features to dataFrame\n",
    "    df_features.loc[audio_index] = [np.mean(librosa.feature.mfcc(y=X, sr=np.array(sample_rate), n_mfcc=13), axis=0)]\n",
    "\n",
    "# Split features column in dataFrame\n",
    "df_features = pd.DataFrame(df_features['features'].values.tolist())\n",
    "\n",
    "# Fill NA values\n",
    "df_features = df_features.fillna(0)\n",
    "\n",
    "# Reshape features for CNN model\n",
    "X = np.expand_dims(np.array(df_features), axis=2)\n",
    "\n",
    "# Prediction\n",
    "pred = model.predict(X, batch_size=1, verbose=0)\n",
    "\n",
    "# Get the index of the max 'probability' for prediction and actual\n",
    "pred = pred.argmax(axis=1)\n",
    "\n",
    "# Reverse label encoder\n",
    "pred = (lb.inverse_transform((pred.astype(int).flatten())))\n",
    "\n",
    "# Build dataFrame\n",
    "df_pred = pd.DataFrame({'Prediction': pred}, index=filenames)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T15:32:56.519212Z",
     "start_time": "2018-12-05T15:32:56.516534Z"
    }
   },
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T15:44:34.301893Z",
     "start_time": "2018-12-05T15:44:34.259574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model file name\n",
    "model_name = 'Emotion_8_Voice_Detection_Model'\n",
    "\n",
    "# Save path\n",
    "save_path = '/Users/anatoli_debradke/Desktop/Speech Emotion Analysis/Librosa and CNN/Models/'\n",
    "\n",
    "# Save model's weights to HDF5 format\n",
    "model.save_weights(save_path + model_name + '.h5')\n",
    "\n",
    "# Save model to JSON format\n",
    "with open(save_path + model_name + '.json', 'w') as json_file:\n",
    "    json_file.write(model.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T22:42:26.707647Z",
     "start_time": "2018-12-05T22:42:26.072031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model file name\n",
    "model_name = 'Emotion_8_Voice_Detection_Model'\n",
    "\n",
    "# model path\n",
    "save_path = '/Users/anatoli_debradke/Desktop/Speech Emotion Analysis/Librosa and CNN/Models/'\n",
    "\n",
    "# Load JSON\n",
    "json_file = open(save_path + model_name + '.json', 'r')\n",
    "\n",
    "# Create model\n",
    "model = model_from_json(json_file.read())\n",
    "\n",
    "# Load weights into model\n",
    "model.load_weights(save_path + model_name + '.h5')\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.rmsprop(lr=0.00001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "# Close model file\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
